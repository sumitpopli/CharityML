{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CharityML project by Sumit Popli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding pre-requiste python packages\n",
    "## These packages are required for processing input data/running\n",
    "## Classifying entries in to earning above 50K  using different ML classification techniques\n",
    "##  model evaluation\n",
    "## model tuning\n",
    "##  visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score,fbeta_score,precision_score,recall_score,confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "#classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB as nb\n",
    "from sklearn.ensemble import AdaBoostClassifier as abc\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing function to encode and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hot encode the following:\n",
    "workclass[1], marital-status[4],occupation[5]\n",
    "race[7], sex[8], native-country[12]\n",
    "scale age, hoursperweek, capital-gains and capital-loss\n",
    "\n",
    "removing education and retaining education num as they have the same information\n",
    "\n",
    "simplifying marital-status and family columns\n",
    "\n",
    "encode income column\n",
    "'''\n",
    "def pre_process_data(profiledata, income):\n",
    "\n",
    "   #removing column education-level from profiledata as education-num has the same information\n",
    "   profiledata = profiledata.drop([2], axis=1)\n",
    "\n",
    "   #marital status and family are columns that provide the same information\n",
    "   #processing both columns to simplify data\n",
    "   profiledata['married'] = np.where(((profiledata[6] == 'Husband') | (profiledata[6] == 'Wife')), 1, 0)\n",
    "\n",
    "   #dropping relationship and marital status from profile data\n",
    "   profiledata = profiledata.drop([6], axis=1)\n",
    "   profiledata = profiledata.drop([4], axis=1)\n",
    "\n",
    "   # scaling all the higher and lower values\n",
    "   std_scaler = StandardScaler()\n",
    "   profiledata.iloc[:, [0, 2, 6, 7, 8]] = std_scaler.fit_transform(profiledata.iloc[:, [0, 2, 6, 7, 8]])\n",
    "\n",
    "   #encoding all the categorical data\n",
    "   profiledata =  pd.get_dummies(profiledata, prefix=['workclass','occupation','race', 'sex', 'native-country'], columns=[1,5,7,8,12])\n",
    "\n",
    "   #scaled and encoded all the reqd fields. removing dummy variable trap: one column for sex will suffice.\n",
    "   #dropping sex_male column\n",
    "   profiledata = profiledata.drop(['sex_ Male'], axis=1)\n",
    "   profiledata = profiledata.interpolate()\n",
    "\n",
    "   if(income is None):\n",
    "       return profiledata, None\n",
    "\n",
    "   #encoding income column\n",
    "   income = pd.get_dummies(income,prefix='income',columns=[0])\n",
    "   #removing <50k column as one column will suffice\n",
    "   income = income.drop(['income_<=50K'], axis=1)\n",
    "   #changing the header name back to 'income'\n",
    "   income.rename(columns={'income_>50K':'income'}, inplace=True)\n",
    "\n",
    "\n",
    "   return profiledata,income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysing data to get insights. Slice data using pandas to see which features play an important role in salary above 50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out how many earn above 50K.\n",
    "#find out stats about education and earnings\n",
    "#find out age and earnings\n",
    "#find out working hrs and earnings\n",
    "#find out profession and earnings\n",
    "#find out marital status and earnings\n",
    "#find out capital gains and earnings\n",
    "\n",
    "def data_insights(censusdata):\n",
    "\n",
    "\n",
    "    #finding how many and % of people donating\n",
    "    earn_50k = censusdata.loc[censusdata[13] == '>50K']\n",
    "    print('========================================')\n",
    "    print('no of people donating vs total no of people is {0}/{1}'.format(earn_50k.shape[0], censusdata.shape[0]))\n",
    "    print('% of people donating is {0}'.format(earn_50k.shape[0]*100/censusdata.shape[0]))\n",
    "    print('========================================')\n",
    "\n",
    "    #finding out stats of how many people with higher degree donate\n",
    "    high_degree = censusdata.loc[(censusdata[3] >= 13) & (censusdata[13] == '>50K')]\n",
    "    print('========================================')\n",
    "    print('no of people with high degree donating is {0}'.format(high_degree.shape[0]))\n",
    "    print('% of people donating that have high degree is {0}'.format(high_degree.shape[0]*100/earn_50k.shape[0]))\n",
    "    print('========================================')\n",
    "\n",
    "    #finding out stats for people above certain age that donate\n",
    "    high_age = censusdata.loc[(censusdata[0]>=40) & (censusdata[13]=='>50K')]\n",
    "    print('========================================')\n",
    "    print('no of people with high age donating is {0}'.format(high_age.shape[0]))\n",
    "    print('% of people donating that have high age is {0}'.format(high_age.shape[0] * 100 / earn_50k.shape[0]))\n",
    "    print('========================================')\n",
    "\n",
    "    #finding out stats for people working normal and higher hours that donate\n",
    "    high_workhrs = censusdata.loc[(censusdata[11]>=40) & (censusdata[13]=='>50K')]\n",
    "    print('========================================')\n",
    "    print('no of people with normal and high working hrs donating is {0}'.format(high_workhrs.shape[0]))\n",
    "    print('% of people donating that have high age is {0}'.format(high_workhrs.shape[0] * 100 / earn_50k.shape[0]))\n",
    "    print('========================================')\n",
    "\n",
    "    #finding out stats for people working in professional jobs\n",
    "    pro_jobs = censusdata.loc[((censusdata[5]=='Prof-specialty')|(censusdata[5]=='Exec-managerial')) & (censusdata[13]=='>50K')]\n",
    "    print('========================================')\n",
    "    print('no of people with professional jobs donating is {0}'.format(pro_jobs.shape[0]))\n",
    "    print('% of people donating that have professional jobs is {0}'.format(pro_jobs.shape[0] * 100 / earn_50k.shape[0]))\n",
    "    print('========================================')\n",
    "\n",
    "    #finding out stats for people who are married\n",
    "    marital_status = censusdata.loc[((censusdata[6] == 'Husband') | (censusdata[6] == 'Wife')) & (censusdata[13] == '>50K')]\n",
    "    print('========================================')\n",
    "    print('no of people with marital status married donating is {0}'.format(marital_status.shape[0]))\n",
    "    print('% of people donating that have marital status married is {0}'.format(marital_status.shape[0] * 100 / earn_50k.shape[0]))\n",
    "    print('========================================')\n",
    "\n",
    "    #finding out stats for people who have capital gains and donate\n",
    "    cap_gains = censusdata.loc[(censusdata[9] > 0) & (censusdata[13] == '>50K')]\n",
    "    print('========================================')\n",
    "    print('no of people with capital gains donating is {0}'.format(cap_gains.shape[0]))\n",
    "    print('% of people donating with capital gains is {0}'.format(cap_gains.shape[0] * 100 / earn_50k.shape[0]))\n",
    "    print('========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accessing the census.csv file to seperate the target variable from features.\n",
    "## calling functions to get data insights to see which features are important, which features need to be combined or dropped\n",
    "## processing Pandas dataframe to encode and scale all variables. \n",
    "## calling different classifier models \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of rows 45222\n",
      "========================================\n",
      "no of people donating vs total no of people is 11208/45222\n",
      "% of people donating is 24.78439697492371\n",
      "========================================\n",
      "========================================\n",
      "no of people with high degree donating is 5562\n",
      "% of people donating that have high degree is 49.62526766595289\n",
      "========================================\n",
      "========================================\n",
      "no of people with high age donating is 7121\n",
      "% of people donating that have high age is 63.534975017844395\n",
      "========================================\n",
      "========================================\n",
      "no of people with normal and high working hrs donating is 10234\n",
      "% of people donating that have high age is 91.30977872947895\n",
      "========================================\n",
      "========================================\n",
      "no of people with professional jobs donating is 5571\n",
      "% of people donating that have professional jobs is 49.70556745182013\n",
      "========================================\n",
      "========================================\n",
      "no of people with marital status married donating is 9523\n",
      "% of people donating that have marital status married is 84.96609564596717\n",
      "========================================\n",
      "========================================\n",
      "no of people with capital gains donating is 2375\n",
      "% of people donating with capital gains is 21.190221270521057\n",
      "========================================\n",
      "          0         3         9       10        11  married  \\\n",
      "0  0.034201  1.128753  0.142888 -0.21878 -0.078120        0   \n",
      "1  0.866417  1.128753 -0.146733 -0.21878 -2.326738        1   \n",
      "2 -0.041455 -0.438122 -0.146733 -0.21878 -0.078120        0   \n",
      "3  1.093385 -1.221559 -0.146733 -0.21878 -0.078120        1   \n",
      "4 -0.798015  1.128753 -0.146733 -0.21878 -0.078120        1   \n",
      "\n",
      "   workclass_ Federal-gov  workclass_ Local-gov  workclass_ Private  \\\n",
      "0                       0                     0                   0   \n",
      "1                       0                     0                   0   \n",
      "2                       0                     0                   1   \n",
      "3                       0                     0                   1   \n",
      "4                       0                     0                   1   \n",
      "\n",
      "   workclass_ Self-emp-inc             ...              \\\n",
      "0                        0             ...               \n",
      "1                        0             ...               \n",
      "2                        0             ...               \n",
      "3                        0             ...               \n",
      "4                        0             ...               \n",
      "\n",
      "   native-country_ Portugal  native-country_ Puerto-Rico  \\\n",
      "0                         0                            0   \n",
      "1                         0                            0   \n",
      "2                         0                            0   \n",
      "3                         0                            0   \n",
      "4                         0                            0   \n",
      "\n",
      "   native-country_ Scotland  native-country_ South  native-country_ Taiwan  \\\n",
      "0                         0                      0                       0   \n",
      "1                         0                      0                       0   \n",
      "2                         0                      0                       0   \n",
      "3                         0                      0                       0   \n",
      "4                         0                      0                       0   \n",
      "\n",
      "   native-country_ Thailand  native-country_ Trinadad&Tobago  \\\n",
      "0                         0                                0   \n",
      "1                         0                                0   \n",
      "2                         0                                0   \n",
      "3                         0                                0   \n",
      "4                         0                                0   \n",
      "\n",
      "   native-country_ United-States  native-country_ Vietnam  \\\n",
      "0                              1                        0   \n",
      "1                              1                        0   \n",
      "2                              1                        0   \n",
      "3                              1                        0   \n",
      "4                              0                        0   \n",
      "\n",
      "   native-country_ Yugoslavia  \n",
      "0                           0  \n",
      "1                           0  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           0  \n",
      "\n",
      "[5 rows x 74 columns]\n",
      "no of rows 45222\n"
     ]
    }
   ],
   "source": [
    "    #read the csv file in to pandas\n",
    "    people_data = pd.read_csv('census.csv',header=None, skiprows=1)\n",
    "\n",
    "    #cleaning up occupation column data for insights\n",
    "    people_data[5] = people_data[5].str.strip()\n",
    "    people_data[6]= people_data[6].str.strip()\n",
    "    print(\"no of rows {0}\".format(people_data.shape[0]))\n",
    "    data_insights(people_data)\n",
    "\n",
    "    #seperate the features from the independent feature\n",
    "    X = people_data.iloc[:,0:13]\n",
    "    y = people_data.iloc[:,13]\n",
    "    processed_X, processed_y = pre_process_data(X,y)\n",
    "\n",
    "    X_train = processed_X\n",
    "    y_train = processed_y\n",
    "    print(X_train.head())\n",
    "\n",
    "    test_people_data = pd.read_csv('test_census.csv',header=None, skiprows=1)\n",
    "    print(\"no of rows {0}\".format(test_people_data.shape[0]))\n",
    "    X_test = test_people_data.iloc[:,1:14]\n",
    "    #reindexing all the columns after the drop\n",
    "    X_test.columns = range(X_test.shape[1])\n",
    "\n",
    "    # cleaning up occupation column data for insights\n",
    "    X_test[5] = X_test[5].str.strip()\n",
    "    X_test[6] = X_test[6].str.strip()\n",
    "    processed_X_test, temp = pre_process_data(X_test, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementing model evaluation function. This function calculates:\n",
    "## accuracy_score (to see how many values did we get right)\n",
    "## Precision (to see how many values predicted as above 50K were actually above 50K)\n",
    "## recall (to see out of all the people above 50K how many were correctly predicted)\n",
    "## f1 score (combination of Precision and recall. Gives good indication of how good the model is)\n",
    "## fbeta (score that indicates how good our precision values are)\n",
    "## ROC and ROC_auc score. Another indicator of how well our model performs. The visual indication helps the user as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_metrics(modelname, y_true, y_pred):\n",
    "    ac = accuracy_score(y_true, y_pred)\n",
    "    ps = precision_score(y_true, y_pred)\n",
    "    rs = recall_score(y_true, y_pred)\n",
    "    f1_s = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fb_4 = fbeta_score(y_true, y_pred,0.4)\n",
    "\n",
    "\n",
    "    print('+++++++++++++++++++++++++++++++')\n",
    "    print('accuracy score:{0}, precision score: {1}, recall score: {2} , f1 score {3}, f0.4 score {4} for {5}'.format(ac, ps, rs, f1_s,fb_4, modelname))\n",
    "    print('+++++++++++++++++++++++++++++++')\n",
    "\n",
    "    false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_true,y_pred)\n",
    "    print('roc_auc_score for {0}: {1} '.format(modelname, roc_auc_score(y_true,y_pred)) )\n",
    "\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plt.subplots(1, figsize=(10, 10))\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate1, true_positive_rate1)\n",
    "    plt.plot([0, 1], ls=\"--\")\n",
    "    plt.plot([0, 0], [1, 0], c=\".7\"), plt.plot([1, 1], c=\".7\")\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementing decision tree classifier function. This function does the following:\n",
    "## uses GridSearchCV to pick the best hyper-parameter value for DTC\n",
    "## runs the model with different combinations\n",
    "## outputs the best hyper-parament combo for best results\n",
    "## lists out feature importance\n",
    "## removes the columns that are not important \n",
    "## runs the model on the data again. \n",
    "## prints out model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "def donation_dtc(X, y, test_data):\n",
    "\n",
    "\n",
    "    parameters = {'criterion': ['gini', 'entropy'], 'max_depth': [8, 10,12,15], 'min_samples_split': [2, 4, 8, 10],'min_samples_leaf': [2, 4, 6, 8, 10]}\n",
    "    scorer = make_scorer(f1_score)\n",
    "\n",
    "    model = dtc(random_state=13)\n",
    "    grid_obj = GridSearchCV(model, parameters, scoring=scorer)\n",
    "    grid_fit = grid_obj.fit(X, y)\n",
    "\n",
    "    best_model_params = grid_fit.best_estimator_\n",
    "    print('best clf is {0}'.format(best_model_params) )\n",
    "    #print('model feature importance: {0}'.format(best_model_params.feature_importances_))\n",
    "    print(dict(zip(X.columns, best_model_params.feature_importances_)))\n",
    "    y_pred = best_model_params.predict(X)\n",
    "    #model_performance_metrics('decision tree classifier (whole training data)', y, y_pred)\n",
    "\n",
    "    model_best = SelectFromModel(best_model_params, prefit=True)\n",
    "    X_new = model_best.transform(X)\n",
    "    print('old Shape of X is {0}'.format(X.shape))\n",
    "    print('new Shape of X is {0}'.format(X_new.shape))\n",
    "\n",
    "\n",
    "    #splitting the training data further to test the model\n",
    "    Xt_train, Xt_test, yt_train, yt_test = train_test_split(X_new,y, test_size=.25, random_state=13)\n",
    "    start_dt = dt.datetime.now()\n",
    "    modelv2 = dtc(criterion='entropy',max_depth=15, min_samples_leaf=2, min_samples_split=10, splitter='best', random_state=13)\n",
    "    modelv2.fit(Xt_train, yt_train)\n",
    "    yt_pred = modelv2.predict(Xt_test)\n",
    "    end_dt = dt.datetime.now()\n",
    "    model_performance_metrics('decision tree classifier (split training data)', yt_test, yt_pred)\n",
    "    delta_dt = end_dt - start_dt\n",
    "    print('time taken (in seconds) for dtc is {0}'.format(delta_dt.total_seconds()))\n",
    "\n",
    "    #now testing against actual data\n",
    "    test_data_new = model_best.transform(test_data)\n",
    "    y_test = modelv2.predict(test_data_new)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementing Random Tree classifier function. This function does the following:\n",
    "## uses GridSearchCV to pick the best hyper-parameter value for rfc\n",
    "## runs the model with different combinations\n",
    "## outputs the best hyper-parament combo for best results\n",
    "## lists out feature importance\n",
    "## removes the columns that are not important \n",
    "## runs the model on the data again. \n",
    "## prints out model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "def donation_rfc(X, y, test_data):\n",
    "\n",
    "    parameters = {'criterion': ['gini', 'entropy'], 'max_depth': [12, 15,18,20,22], 'min_samples_split': [4, 8, 10],\n",
    "                  'min_samples_leaf': [4, 6, 8, 10],'n_estimators': [50, 100, 150]}\n",
    "    scorer = make_scorer(f1_score)\n",
    "\n",
    "    model = rfc(random_state=13)\n",
    "    grid_obj = GridSearchCV(model, parameters, scoring=scorer)\n",
    "    grid_fit = grid_obj.fit(X, y.values.ravel())\n",
    "\n",
    "    best_model_params = grid_fit.best_estimator_\n",
    "    print('best clf is {0}'.format(best_model_params))\n",
    "    # print('model feature importance: {0}'.format(best_model_params.feature_importances_))\n",
    "    print(dict(zip(X.columns, best_model_params.feature_importances_)))\n",
    "    y_pred = best_model_params.predict(X)\n",
    "    #model_performance_metrics('random forest classifier (whole training data)', y, y_pred)\n",
    "\n",
    "    model_best = SelectFromModel(best_model_params, prefit=True)\n",
    "    X_new = model_best.transform(X)\n",
    "    print('old Shape of X is {0}'.format(X.shape))\n",
    "    print('new Shape of X is {0}'.format(X_new.shape))\n",
    "\n",
    "    #splitting the training data further to test the model\n",
    "    Xt_train, Xt_test, yt_train, yt_test = train_test_split(X_new,y, test_size=.25, random_state=13)\n",
    "    start_dt = dt.datetime.now()\n",
    "    modelv2 = rfc(bootstrap=True, criterion='entropy', max_depth=20,max_features='auto', min_samples_leaf= 4, min_samples_split= 4, n_estimators= 150, warm_start= False, oob_score= False ,random_state=13)\n",
    "    modelv2.fit(Xt_train, yt_train.values.ravel())\n",
    "    yt_pred = modelv2.predict(Xt_test)\n",
    "    end_dt = dt.datetime.now()\n",
    "    model_performance_metrics('random forest classifier (split train data)',yt_test, yt_pred)\n",
    "    delta_dt = end_dt - start_dt\n",
    "    print('time taken (in seconds) for rfc is {0}'.format(delta_dt.total_seconds()))\n",
    "\n",
    "    # now testing against actual data\n",
    "    test_data_new = model_best.transform(test_data)\n",
    "    y_test = modelv2.predict(test_data_new)\n",
    "    return y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementing Ada boost classifier function. This function does the following:\n",
    "## uses GridSearchCV to pick the best hyper-parameter value for abc\n",
    "## runs the model with different combinations\n",
    "## outputs the best hyper-parament combo for best results\n",
    "## lists out feature importance\n",
    "## removes the columns that are not important \n",
    "## runs the model on the data again. \n",
    "## prints out model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada boost classifier\n",
    "def donation_abc(X, y, test_data):\n",
    "    #setting up hyper parameter\n",
    "    parameters = {'learning_rate': [0.2,0.5,1], 'algorithm': ['SAMME', 'SAMME.R'],'n_estimators': [75, 100, 150]}\n",
    "    scorer = make_scorer(f1_score)\n",
    "\n",
    "    base_model = dtc(min_samples_leaf=2, min_samples_split=10,criterion='entropy',max_depth=15)\n",
    "    model = abc(base_estimator = base_model,random_state=13)\n",
    "    # taking the training data and fitting in to the model\n",
    "    grid_obj = GridSearchCV(model, parameters, scoring=scorer)\n",
    "    grid_fit = grid_obj.fit(X, y.values.ravel())\n",
    "\n",
    "    best_model_params = grid_fit.best_estimator_\n",
    "    print('best clf is {0}'.format(best_model_params))\n",
    "    # print('model feature importance: {0}'.format(best_model_params.feature_importances_))\n",
    "    print(dict(zip(X.columns, best_model_params.feature_importances_)))\n",
    "    y_pred = best_model_params.predict(X)\n",
    "    #model_performance_metrics('ada boost classifier (whole training data)',y, y_pred)\n",
    "\n",
    "    model_best = SelectFromModel(best_model_params, prefit=True)\n",
    "    X_new = model_best.transform(X)\n",
    "    print('old Shape of X is {0}'.format(X.shape))\n",
    "    print('new Shape of X is {0}'.format(X_new.shape))\n",
    "\n",
    "    # splitting the training data further to test the model\n",
    "    Xt_train, Xt_test, yt_train, yt_test = train_test_split(X_new, y, test_size=.25, random_state=13)\n",
    "\n",
    "    start_dt = dt.datetime.now()\n",
    "    modelv2 = abc(algorithm='SAMME',base_estimator=dtc(ccp_alpha=0.0,class_weight=None,criterion='entropy',max_depth=15,max_features=None,max_leaf_nodes=None,\n",
    "                                                         min_impurity_decrease=0.0,min_impurity_split=None,min_samples_leaf=2,min_samples_split=10,min_weight_fraction_leaf=0.0,\n",
    "                                                         presort='deprecated',random_state=None,splitter='best'),learning_rate=0.2, n_estimators=150, random_state=13)\n",
    "    # taking the training data and fitting in to the model\n",
    "    modelv2.fit(Xt_train, yt_train.values.ravel())\n",
    "    yt_pred = modelv2.predict(Xt_test)\n",
    "    end_dt = dt.datetime.now()\n",
    "    model_performance_metrics('ada boost classifier (split train data)',yt_test,yt_pred)\n",
    "    delta_dt = end_dt - start_dt\n",
    "    print('time taken (in seconds) for abc in minutes is {0}'.format(delta_dt.total_seconds()))\n",
    "\n",
    "    # now testing against actual data\n",
    "    test_data_new = model_best.transform(test_data)\n",
    "    y_test = modelv2.predict(test_data_new)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_svc(X, y, test_data):\n",
    "\n",
    "    #splitting the training data further to test the model\n",
    "    Xt_train, Xt_test, yt_train, yt_test = train_test_split(X,y, test_size=.25, random_state=13)\n",
    "    start_dt = dt.datetime.now()\n",
    "    modelv2 = SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,decision_function_shape='ovr', degree=2, gamma='scale', kernel='rbf', max_iter=-1, probability=False, random_state=13, shrinking=True, tol=0.001, verbose=False)\n",
    "    modelv2.fit(Xt_train, yt_train.values.ravel())\n",
    "    yt_pred = modelv2.predict(Xt_test)\n",
    "    end_dt = dt.datetime.now()\n",
    "    model_performance_metrics('support vector classifier (split training data)', yt_test, yt_pred)\n",
    "    delta_dt = end_dt - start_dt\n",
    "    print('time taken (in seconds) for svc is {0}'.format(delta_dt.total_seconds()))\n",
    "\n",
    "    # now testing against actual data\n",
    "    y_test = modelv2.predict(test_data)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calling different classifier functions to check which one is the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_result_index_col = np.asarray(test_people_data.iloc[:, 0])\n",
    "    test_result_index_col = test_result_index_col.reshape(-1, 1)\n",
    "\n",
    "    dtc_income_data = donation_dtc(X_train, y_train, processed_X_test)\n",
    "    dtc_income_data = dtc_income_data.reshape(-1,1)\n",
    "    dtc_test_score = np.append(test_result_index_col, dtc_income_data,axis=1)\n",
    "\n",
    "\n",
    "    rfc_income_data = donation_rfc(X_train, y_train, processed_X_test)\n",
    "    rfc_income_data = rfc_income_data.reshape(-1, 1)\n",
    "    rfc_test_score = np.append(test_result_index_col, rfc_income_data, axis=1)\n",
    "\n",
    "    svc_income_data = donation_svc(X_train, y_train, processed_X_test)\n",
    "    svc_income_data = svc_income_data.reshape(-1,1)\n",
    "    svc_test_score = np.append(test_result_index_col, svc_income_data, axis=1)\n",
    "\n",
    "    abc_income_data = donation_abc(X_train, y_train, processed_X_test)\n",
    "    abc_income_data = abc_income_data.reshape(-1, 1)\n",
    "    abc_test_score = np.append(test_result_index_col, abc_income_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
